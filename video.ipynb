{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95c2384",
   "metadata": {},
   "source": [
    "## Regime Switching for Pairs Trading\n",
    "\n",
    "When trading a spread between two correlated assets (like BTC and ETH), the key question is:\n",
    "**when should I enter and exit positions?**\n",
    "\n",
    "Let's look at real data to see why this is tricky..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2h1mk8qe2tu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fetch_data import fetch_btc_eth_history\n",
    "\n",
    "# Fetch 17 days of hourly BTC/ETH data\n",
    "plt.style.use(\"dark_background\")\n",
    "df = fetch_btc_eth_history(days=17, interval=\"1h\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(df[\"open_time\"], df[\"log_ratio\"], color=\"cyan\", linewidth=1.2)\n",
    "ax.set_xlabel(\"Date\", fontsize=11)\n",
    "ax.set_ylabel(\"log(BTC/ETH)\", fontsize=11)\n",
    "ax.set_title(\"BTC/ETH Spread: When Should We Enter and Exit?\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arcdwhp7mfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_data import estimate_ou_parameters\n",
    "\n",
    "# Split into training (first 14 days) and test (last 3 days)\n",
    "spread = df[\"log_ratio\"].values\n",
    "times = df[\"open_time\"]\n",
    "dt = 1 / 24  # hourly data = 1/24 of a day\n",
    "\n",
    "train_hours = 14 * 24\n",
    "train_spread = spread[:train_hours]\n",
    "train_times = times[:train_hours]\n",
    "test_spread = spread[train_hours:]\n",
    "test_times = times[train_hours:]\n",
    "\n",
    "# Estimate parameters from training period only\n",
    "params = estimate_ou_parameters(train_spread, dt)\n",
    "mu = train_spread.mean()  # Use empirical mean\n",
    "sigma = train_spread.std()  # Use empirical std dev (not OU sigma)\n",
    "\n",
    "print(f\"Parameters estimated from first 14 days:\")\n",
    "print(f\"  Mean (μ): {mu:.4f}\")\n",
    "print(f\"  Std dev (σ): {sigma:.4f}\")\n",
    "print(f\"  OU half-life: {params['half_life']*24:.1f} hours\")\n",
    "\n",
    "# Visualize both periods\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "for ax, s, t, title in [\n",
    "    (axes[0], train_spread, train_times, \"Training Period: 14 days (parameters estimated here)\"),\n",
    "    (axes[1], test_spread, test_times, \"Test Period: 3 days (how would it perform?)\")\n",
    "]:\n",
    "    ax.plot(t, s, color=\"cyan\", linewidth=1.2)\n",
    "    ax.axhline(mu, color=\"white\", linestyle=\"--\", linewidth=1.5, label=f\"μ = {mu:.3f}\")\n",
    "    ax.fill_between(t, mu - sigma, mu + sigma, color=\"green\", alpha=0.25, label=\"±1σ\")\n",
    "    ax.fill_between(t, mu - 2*sigma, mu - sigma, color=\"red\", alpha=0.25, label=\"±2σ\")\n",
    "    ax.fill_between(t, mu + sigma, mu + 2*sigma, color=\"red\", alpha=0.25)\n",
    "    ax.set_xlabel(\"Date\", fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "axes[0].set_ylabel(\"log(BTC/ETH)\", fontsize=11)\n",
    "axes[0].legend(loc=\"upper right\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9wme2weeie8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_threshold(spread: np.ndarray, mu: float, threshold: float, fee: float = 0.001) -> float:\n",
    "    \"\"\"\n",
    "    Backtest a simple threshold strategy on spread data.\n",
    "    \n",
    "    Strategy:\n",
    "    - Go long when spread < mu - threshold (expect reversion up)\n",
    "    - Go short when spread > mu + threshold (expect reversion down)\n",
    "    - Exit (go flat) when spread crosses mu\n",
    "    \n",
    "    Returns total PnL after fees.\n",
    "    \"\"\"\n",
    "    position = 0  # -1 short, 0 flat, +1 long\n",
    "    pnl = 0.0\n",
    "    entry_price = 0.0\n",
    "    \n",
    "    for i in range(1, len(spread)):\n",
    "        price = spread[i]\n",
    "        prev_price = spread[i-1]\n",
    "        \n",
    "        # Check for exit first (cross the mean)\n",
    "        if position == 1 and price >= mu:  # Long position, crossed above mean\n",
    "            pnl += (price - entry_price) - fee\n",
    "            position = 0\n",
    "        elif position == -1 and price <= mu:  # Short position, crossed below mean\n",
    "            pnl += (entry_price - price) - fee\n",
    "            position = 0\n",
    "        \n",
    "        # Check for entry\n",
    "        if position == 0:\n",
    "            if price < mu - threshold:  # Enter long\n",
    "                position = 1\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "            elif price > mu + threshold:  # Enter short\n",
    "                position = -1\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "    \n",
    "    # Close any open position at end\n",
    "    if position == 1:\n",
    "        pnl += (spread[-1] - entry_price)\n",
    "    elif position == -1:\n",
    "        pnl += (entry_price - spread[-1])\n",
    "    \n",
    "    return pnl\n",
    "\n",
    "# Find the best threshold on training data (overfit!)\n",
    "thresholds = np.linspace(0.001, 3 * sigma, 50)\n",
    "train_pnls = [backtest_threshold(train_spread, mu, t) for t in thresholds]\n",
    "best_idx = np.argmax(train_pnls)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_train_pnl = train_pnls[best_idx]\n",
    "\n",
    "# Now test it out-of-sample\n",
    "test_pnl = backtest_threshold(test_spread, mu, best_threshold)\n",
    "\n",
    "print(f\"Best threshold (overfit to training): {best_threshold:.4f} ({best_threshold/sigma:.2f}σ)\")\n",
    "print(f\"Training PnL: {best_train_pnl:.4f}\")\n",
    "print(f\"Test PnL:     {test_pnl:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "for ax, s, t, title, pnl in [\n",
    "    (axes[0], train_spread, train_times, f\"Training: 14 days (PnL: {best_train_pnl:.4f})\", best_train_pnl),\n",
    "    (axes[1], test_spread, test_times, f\"Test: 3 days (PnL: {test_pnl:.4f})\", test_pnl)\n",
    "]:\n",
    "    ax.plot(t, s, color=\"cyan\", linewidth=1.2)\n",
    "    ax.axhline(mu, color=\"white\", linestyle=\"--\", linewidth=1.5, label=f\"μ = {mu:.3f}\")\n",
    "    ax.axhline(mu + best_threshold, color=\"red\", linestyle=\":\", linewidth=1.5, label=f\"±{best_threshold/sigma:.2f}σ threshold\")\n",
    "    ax.axhline(mu - best_threshold, color=\"red\", linestyle=\":\", linewidth=1.5)\n",
    "    ax.fill_between(t, mu - best_threshold, mu + best_threshold, color=\"gray\", alpha=0.15)\n",
    "    ax.set_xlabel(\"Date\", fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "axes[0].set_ylabel(\"log(BTC/ETH)\", fontsize=11)\n",
    "axes[0].legend(loc=\"upper right\", fontsize=9)\n",
    "\n",
    "plt.suptitle(\"Overfit Strategy: Best Threshold on Training Data\", fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba8819",
   "metadata": {},
   "source": [
    "## Paper Simplfied\n",
    "https://arxiv.org/abs/2512.04697v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fmuzudr3tb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pairs_trading import SWITCHING_COSTS, R_FUNDING, R_CASH\n",
    "from regime_switching import Config, train\n",
    "\n",
    "# Use OU parameters estimated from the ACTUAL training data\n",
    "# (params, mu, sigma were computed in an earlier cell from train_spread)\n",
    "THETA_REAL = params[\"theta\"]  # Mean-reversion speed (per day)\n",
    "MU_REAL = mu                   # Empirical mean of training spread\n",
    "SIGMA_REAL = params[\"sigma\"]   # OU volatility (per sqrt(day))\n",
    "SPREAD_SCALE_REAL = sigma      # Use empirical std dev as scale\n",
    "\n",
    "print(f\"OU parameters from training data:\")\n",
    "print(f\"  θ (mean-reversion): {THETA_REAL:.2f} per day\")\n",
    "print(f\"  μ (long-term mean): {MU_REAL:.4f}\")\n",
    "print(f\"  σ (OU volatility):  {SIGMA_REAL:.4f} per sqrt(day)\")\n",
    "print(f\"  Scale (empirical σ): {SPREAD_SCALE_REAL:.4f}\")\n",
    "print()\n",
    "\n",
    "# Define dynamics using REAL parameters\n",
    "def dynamics_fn_real(t: torch.Tensor, x: torch.Tensor, i: torch.Tensor\n",
    "                     ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"OU dynamics using parameters estimated from actual training data.\"\"\"\n",
    "    drift = -THETA_REAL * x  # Mean-reverts to 0 (in normalized space)\n",
    "    diffusion = torch.full_like(x, SIGMA_REAL / SPREAD_SCALE_REAL)\n",
    "    return drift, diffusion\n",
    "\n",
    "def running_reward_fn_real(t: torch.Tensor, x: torch.Tensor, i: torch.Tensor\n",
    "                           ) -> torch.Tensor:\n",
    "    \"\"\"Running reward using real parameters.\"\"\"\n",
    "    drift_profit_long = -THETA_REAL * SPREAD_SCALE_REAL * x\n",
    "    drift_profit_short = THETA_REAL * SPREAD_SCALE_REAL * x\n",
    "    \n",
    "    reward_long = drift_profit_long - R_FUNDING\n",
    "    reward_short = drift_profit_short - R_FUNDING\n",
    "    reward_flat = torch.full_like(x, R_CASH)\n",
    "    \n",
    "    return torch.where(i == 0, reward_long, \n",
    "                       torch.where(i == 1, reward_short, reward_flat))\n",
    "\n",
    "def terminal_reward_real(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Terminal reward h = 0.\"\"\"\n",
    "    return torch.zeros(x.shape[0], device=x.device)\n",
    "\n",
    "# Training config\n",
    "config = Config(\n",
    "    num_regimes=3, state_dim=1,\n",
    "    switching_costs=SWITCHING_COSTS,\n",
    "    temperature=0.1,\n",
    "    T=2.0/24.0, K=120,  # 2 hours horizon, 1 step per minute\n",
    "    batch_size=256, num_episodes=200,\n",
    "    learning_rate=1e-3, hidden_dim=64,\n",
    "    x0_mean=0.0,  # Normalized: 0 = at the mean\n",
    "    x0_std=1.0,   # Normalized: 1 std = 1 unit\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}...\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "value_net, losses = train(config, terminal_reward_real, dynamics_fn_real, \n",
    "                          running_reward_fn_real, device)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluate learned policy across spread values\n",
    "value_net.eval()\n",
    "spread_range = torch.linspace(-3.0, 3.0, 500, device=device)  # ±3 std devs\n",
    "t_mid = torch.full_like(spread_range, config.T / 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    values = value_net(t_mid, spread_range)\n",
    "    v_long = values[:, 0].cpu().numpy()\n",
    "    v_short = values[:, 1].cpu().numpy()\n",
    "    v_flat = values[:, 2].cpu().numpy()\n",
    "\n",
    "spread_np = spread_range.cpu().numpy()\n",
    "\n",
    "# Calculate switching thresholds accounting for costs\n",
    "cost_matrix = np.array(SWITCHING_COSTS)\n",
    "switching_thresholds = {}\n",
    "\n",
    "# Short -> Long: switch when V_long - V_short > cost[1,0]\n",
    "diff_short_to_long = v_long - v_short\n",
    "cost_short_to_long = cost_matrix[1, 0]\n",
    "switch_short_to_long_idx = np.where(diff_short_to_long > cost_short_to_long)[0]\n",
    "if len(switch_short_to_long_idx) > 0:\n",
    "    switching_thresholds['Short→Long'] = spread_np[switch_short_to_long_idx[-1]]\n",
    "\n",
    "# Long -> Short: switch when V_short - V_long > cost[0,1]\n",
    "diff_long_to_short = v_short - v_long\n",
    "cost_long_to_short = cost_matrix[0, 1]\n",
    "switch_long_to_short_idx = np.where(diff_long_to_short > cost_long_to_short)[0]\n",
    "if len(switch_long_to_short_idx) > 0:\n",
    "    switching_thresholds['Long→Short'] = spread_np[switch_long_to_short_idx[0]]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left plot: Value functions\n",
    "ax = axes[0]\n",
    "ax.plot(spread_np, v_long, 'b-', label='V(Long)', linewidth=2)\n",
    "ax.plot(spread_np, v_short, 'r-', label='V(Short)', linewidth=2)\n",
    "ax.plot(spread_np, v_flat, 'g-', label='V(Flat)', linewidth=2, alpha=0.7)\n",
    "\n",
    "optimal_regime = np.argmax([v_long, v_short, v_flat], axis=0)\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i in range(len(spread_np) - 1):\n",
    "    ax.axvspan(spread_np[i], spread_np[i+1], alpha=0.1, color=colors[optimal_regime[i]])\n",
    "\n",
    "ax.axvline(x=0, color='yellow', linestyle=':', alpha=0.5, label='Mean (μ)')\n",
    "ax.set_xlabel('Normalized Spread (std devs from mean)', fontsize=12)\n",
    "ax.set_ylabel('Value Function', fontsize=12)\n",
    "ax.set_title('Optimal Regime (if starting fresh)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Switching thresholds\n",
    "ax = axes[1]\n",
    "advantage_to_long = v_long - v_short - cost_short_to_long\n",
    "advantage_to_short = v_short - v_long - cost_long_to_short\n",
    "\n",
    "ax.fill_between(spread_np, 0, advantage_to_long, where=advantage_to_long > 0, \n",
    "                alpha=0.3, color='blue', label='Switch to Long profitable')\n",
    "ax.fill_between(spread_np, 0, advantage_to_short, where=advantage_to_short > 0,\n",
    "                alpha=0.3, color='red', label='Switch to Short profitable')\n",
    "ax.axhline(0, color='white', linestyle='-', alpha=0.5)\n",
    "\n",
    "if 'Short→Long' in switching_thresholds:\n",
    "    x = switching_thresholds['Short→Long']\n",
    "    ax.axvline(x=x, color='cyan', linestyle='--', linewidth=2, label=f'Short→Long @ {x:.2f}σ')\n",
    "if 'Long→Short' in switching_thresholds:\n",
    "    x = switching_thresholds['Long→Short']\n",
    "    ax.axvline(x=x, color='orange', linestyle='--', linewidth=2, label=f'Long→Short @ {x:.2f}σ')\n",
    "\n",
    "ax.set_xlabel('Normalized Spread (std devs from mean)', fontsize=12)\n",
    "ax.set_ylabel('Net Advantage (after cost)', fontsize=12)\n",
    "ax.set_title('When to Actually Switch (accounting for costs)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print trading rules\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEARNED SWITCHING RULES (trained on actual data parameters)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nThresholds in normalized units (std devs from training mean):\")\n",
    "\n",
    "if 'Short→Long' in switching_thresholds and 'Long→Short' in switching_thresholds:\n",
    "    x_s2l = switching_thresholds['Short→Long']\n",
    "    x_l2s = switching_thresholds['Long→Short']\n",
    "    \n",
    "    print(f\"  Short→Long threshold: {x_s2l:.2f}σ\")\n",
    "    print(f\"  Long→Short threshold: {x_l2s:.2f}σ\")\n",
    "    print(f\"  Hysteresis gap: {x_l2s - x_s2l:.2f}σ\")\n",
    "    print()\n",
    "    \n",
    "    # Convert to raw values\n",
    "    raw_s2l = x_s2l * SPREAD_SCALE_REAL + MU_REAL\n",
    "    raw_l2s = x_l2s * SPREAD_SCALE_REAL + MU_REAL\n",
    "    \n",
    "    print(f\"In raw spread values:\")\n",
    "    print(f\"  Switch to LONG when spread < {raw_s2l:.4f}\")\n",
    "    print(f\"  Switch to SHORT when spread > {raw_l2s:.4f}\")\n",
    "else:\n",
    "    print(\"Could not find clear switching thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3lxls7elbtp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply learned thresholds to real data with HYSTERESIS\n",
    "# Convert thresholds from normalized (std devs) to raw spread values\n",
    "threshold_short_to_long_raw = switching_thresholds['Short→Long'] * SPREAD_SCALE_REAL + MU_REAL\n",
    "threshold_long_to_short_raw = switching_thresholds['Long→Short'] * SPREAD_SCALE_REAL + MU_REAL\n",
    "\n",
    "def backtest_hysteresis(spread: np.ndarray, thresh_s2l: float, thresh_l2s: float, \n",
    "                        fee: float = 0.001) -> tuple[float, list]:\n",
    "    \"\"\"\n",
    "    Backtest with hysteresis: different thresholds for entering Long vs Short.\n",
    "    \n",
    "    - If Short: switch to Long when spread < thresh_s2l\n",
    "    - If Long: switch to Short when spread > thresh_l2s\n",
    "    - Start Flat, enter Long below thresh_s2l, enter Short above thresh_l2s\n",
    "    \n",
    "    Returns (total_pnl, position_history)\n",
    "    \"\"\"\n",
    "    position = 0  # -1 short, 0 flat, +1 long\n",
    "    pnl = 0.0\n",
    "    entry_price = 0.0\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(len(spread)):\n",
    "        price = spread[i]\n",
    "        \n",
    "        if position == 0:  # Flat - look for entry\n",
    "            if price < thresh_s2l:\n",
    "                position = 1  # Go long\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "            elif price > thresh_l2s:\n",
    "                position = -1  # Go short\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "        elif position == 1:  # Long - check for switch to short\n",
    "            if price > thresh_l2s:\n",
    "                # Close long and open short\n",
    "                pnl += (price - entry_price) - fee\n",
    "                position = -1\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "        elif position == -1:  # Short - check for switch to long\n",
    "            if price < thresh_s2l:\n",
    "                # Close short and open long\n",
    "                pnl += (entry_price - price) - fee\n",
    "                position = 1\n",
    "                entry_price = price\n",
    "                pnl -= fee\n",
    "        \n",
    "        positions.append(position)\n",
    "    \n",
    "    # Close any open position at end\n",
    "    if position == 1:\n",
    "        pnl += (spread[-1] - entry_price)\n",
    "    elif position == -1:\n",
    "        pnl += (entry_price - spread[-1])\n",
    "    \n",
    "    return pnl, positions\n",
    "\n",
    "# Run backtest on both periods\n",
    "train_pnl_rl, train_positions = backtest_hysteresis(train_spread, threshold_short_to_long_raw, \n",
    "                                                     threshold_long_to_short_raw)\n",
    "test_pnl_rl, test_positions = backtest_hysteresis(test_spread, threshold_short_to_long_raw,\n",
    "                                                   threshold_long_to_short_raw)\n",
    "\n",
    "print(f\"RL Learned Thresholds (with hysteresis):\")\n",
    "print(f\"  Switch to Long when spread < {threshold_short_to_long_raw:.4f} ({switching_thresholds['Short→Long']:.2f}σ)\")\n",
    "print(f\"  Switch to Short when spread > {threshold_long_to_short_raw:.4f} ({switching_thresholds['Long→Short']:.2f}σ)\")\n",
    "print(f\"  Hysteresis gap: {threshold_long_to_short_raw - threshold_short_to_long_raw:.4f}\")\n",
    "print()\n",
    "print(f\"Training PnL (RL): {train_pnl_rl:.4f}\")\n",
    "print(f\"Test PnL (RL):     {test_pnl_rl:.4f}\")\n",
    "\n",
    "# Compare to naive strategy\n",
    "print(f\"\\nComparison to naive overfit strategy:\")\n",
    "print(f\"  Naive Training PnL: {best_train_pnl:.4f}\")\n",
    "print(f\"  Naive Test PnL:     {test_pnl:.4f}\")\n",
    "\n",
    "# Visualize with position coloring\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "for ax, s, t, pos, title in [\n",
    "    (axes[0], train_spread, train_times, train_positions, \n",
    "     f\"Training: 14 days (RL PnL: {train_pnl_rl:.4f})\"),\n",
    "    (axes[1], test_spread, test_times, test_positions,\n",
    "     f\"Test: 3 days (RL PnL: {test_pnl_rl:.4f})\")\n",
    "]:\n",
    "    # Plot spread\n",
    "    ax.plot(t, s, color=\"cyan\", linewidth=1.2, zorder=3)\n",
    "    \n",
    "    # Shade by position\n",
    "    pos_arr = np.array(pos)\n",
    "    t_arr = np.array(t)\n",
    "    for i in range(len(s) - 1):\n",
    "        if pos_arr[i] == 1:  # Long\n",
    "            ax.axvspan(t_arr[i], t_arr[i+1], alpha=0.3, color='blue')\n",
    "        elif pos_arr[i] == -1:  # Short\n",
    "            ax.axvspan(t_arr[i], t_arr[i+1], alpha=0.3, color='red')\n",
    "    \n",
    "    # Draw thresholds\n",
    "    ax.axhline(threshold_short_to_long_raw, color='cyan', linestyle='--', linewidth=2, \n",
    "               label=f'Long @ {switching_thresholds[\"Short→Long\"]:.2f}σ')\n",
    "    ax.axhline(threshold_long_to_short_raw, color='orange', linestyle='--', linewidth=2,\n",
    "               label=f'Short @ {switching_thresholds[\"Long→Short\"]:.2f}σ')\n",
    "    \n",
    "    # Mean line\n",
    "    ax.axhline(MU_REAL, color='white', linestyle=':', alpha=0.5, label=f'μ = {MU_REAL:.3f}')\n",
    "    \n",
    "    # Hysteresis zone\n",
    "    ax.fill_between(t, threshold_short_to_long_raw, threshold_long_to_short_raw, \n",
    "                    color='gray', alpha=0.2, label='Hysteresis zone')\n",
    "    \n",
    "    ax.set_xlabel(\"Date\", fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "axes[0].set_ylabel(\"log(BTC/ETH)\", fontsize=11)\n",
    "axes[0].legend(loc=\"upper right\", fontsize=9)\n",
    "\n",
    "plt.suptitle(\"RL Strategy with Hysteresis: Learned Switching Thresholds\", \n",
    "             fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STRATEGY COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Strategy':<25} {'Train PnL':>12} {'Test PnL':>12}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Naive (overfit σ)':<25} {best_train_pnl:>12.4f} {test_pnl:>12.4f}\")\n",
    "print(f\"{'RL (hysteresis)':<25} {train_pnl_rl:>12.4f} {test_pnl_rl:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mhuxjcrxk3",
   "metadata": {},
   "source": [
    "## How Does This Work?\n",
    "\n",
    "### Step 1: Model the spread as a diffusion process\n",
    "\n",
    "We assume the spread follows an **Ornstein-Uhlenbeck (OU) process**:\n",
    "\n",
    "$$dS = \\theta(\\mu - S)dt + \\sigma dW$$\n",
    "\n",
    "In plain English:\n",
    "- **S** = current spread value\n",
    "- **θ(μ - S)** = \"pull toward the mean\" — if S is above μ, this is negative (pulls down); if S is below μ, this is positive (pulls up)\n",
    "- **θ** = how strong the pull is (higher = faster mean-reversion)\n",
    "- **σdW** = random noise (Brownian motion)\n",
    "\n",
    "This is just a fancy way of saying: **\"the spread tends to revert to its mean, plus some randomness\"**\n",
    "\n",
    "We estimate θ, μ, and σ from the training data using linear regression on the changes in spread.\n",
    "\n",
    "### Step 2-4: The RL Pipeline\n",
    "\n",
    "2. **Simulate many paths** — Using the fitted OU model, generate thousands of synthetic trajectories\n",
    "\n",
    "3. **Learn the value function** — A neural network learns V(x, regime) = \"expected future reward starting from spread x in this regime\"\n",
    "\n",
    "4. **Extract thresholds** — Query where V(Long) > V(Short) + switching_cost to find optimal switching points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r0i1hb2226o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: What does \"simulate many paths\" look like?\n",
    "# Here are 20 sample trajectories the RL agent might see during training\n",
    "\n",
    "def simulate_ou_path(x0: float, theta: float, sigma: float, dt: float, n_steps: int) -> np.ndarray:\n",
    "    \"\"\"Simulate a single OU path (in normalized space where mean=0).\"\"\"\n",
    "    path = np.zeros(n_steps)\n",
    "    path[0] = x0\n",
    "    for i in range(1, n_steps):\n",
    "        drift = -theta * path[i-1] * dt\n",
    "        diffusion = sigma * np.sqrt(dt) * np.random.randn()\n",
    "        path[i] = path[i-1] + drift + diffusion\n",
    "    return path\n",
    "\n",
    "# Simulation parameters (matching training config)\n",
    "n_paths = 20\n",
    "n_steps = 120  # 2 hours at 1 step/min\n",
    "dt_sim = (2.0/24.0) / n_steps  # Time step in days\n",
    "\n",
    "# Use the OU parameters we estimated from real data\n",
    "theta_sim = THETA_REAL\n",
    "sigma_sim = SIGMA_REAL / SPREAD_SCALE_REAL  # Normalized volatility\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Simulate paths starting from different points\n",
    "np.random.seed(42)\n",
    "for _ in range(n_paths):\n",
    "    x0 = np.random.randn() * 1.0  # Start from random point ~N(0,1)\n",
    "    path = simulate_ou_path(x0, theta_sim, sigma_sim, dt_sim, n_steps)\n",
    "    ax.plot(path, alpha=0.5, linewidth=1)\n",
    "\n",
    "ax.axhline(0, color='yellow', linestyle='--', linewidth=2, label='Mean (μ)')\n",
    "ax.axhline(-switching_thresholds['Short→Long'], color='cyan', linestyle=':', \n",
    "           label=f'Long threshold ({switching_thresholds[\"Short→Long\"]:.2f}σ)')\n",
    "ax.axhline(-switching_thresholds['Long→Short'], color='orange', linestyle=':',\n",
    "           label=f'Short threshold ({switching_thresholds[\"Long→Short\"]:.2f}σ)')\n",
    "\n",
    "ax.set_xlabel('Time Step (minutes)', fontsize=11)\n",
    "ax.set_ylabel('Normalized Spread (σ from mean)', fontsize=11)\n",
    "ax.set_title('Simulated OU Paths: What the RL Agent \"Sees\" During Training', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Each path: {n_steps} steps over {config.T*24*60:.0f} minutes\")\n",
    "print(f\"The agent learns which regime (Long/Short/Flat) maximizes reward across all these scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfmoohh3uat",
   "metadata": {},
   "source": [
    "## The Value Function Intuition\n",
    "\n",
    "**V(x, regime)** = expected future profit if we're at spread x in the given regime\n",
    "\n",
    "- Where **V(Long) > V(Short)**: being Long is more valuable\n",
    "- Where **V(Short) > V(Long)**: being Short is more valuable\n",
    "- The **switching cost** creates hysteresis — we don't flip-flop at x=0, we wait until the benefit exceeds the cost\n",
    "\n",
    "This is why the learned thresholds aren't symmetric around the mean. The model accounts for transaction costs and finds the optimal \"buffer zone\" where you should hold your current position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regime-switching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
